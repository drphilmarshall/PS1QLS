{
 "metadata": {
  "name": "",
  "signature": "sha256:ac3c74f548f2c0a0e73c980eb96d51d1fec21f7e29671138aae58b4c6d8031a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from IPython.html.widgets import interact, interactive, fixed\n",
      "from IPython.html import widgets\n",
      "dataLoc = '../../'\n",
      "\n",
      "labels = ['ID','mag_model_i','g-r', 'r-i', 'i-z', 'WISE1', 'WISE2' ]\n",
      "pQSO = np.loadtxt(dataLoc+'pQSO/pSDSScolmag.txt')\n",
      "lQSO = np.loadtxt(dataLoc+'lQSO/SDSScolmag.txt')\n",
      "sinQSO = np.loadtxt(dataLoc+'sinQSO/sSDSScolmag.txt')\n",
      "unlQSO = np.loadtxt(dataLoc+'unlQSO/nlSDSScolmag.txt')\n",
      "unlQSO[:,5:7] = -unlQSO[:,5:7] #bug in WISE magnitudes for this file\n",
      "\n",
      "data = np.concatenate((lQSO,pQSO,unlQSO,sinQSO),axis=0)\n",
      "truth = np.concatenate((np.ones(lQSO.shape[0]),np.zeros(data.shape[0] - lQSO.shape[0])))\n",
      "numPts = data.shape[0]\n",
      "data = data[:,1:] #don't use IDs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "dataTrain, dataTest, truthTrain, truthTest = train_test_split(data, truth, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Random Forests: Out-of-the-box"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=200,oob_score=True)\n",
      "myRF = clf.fit(dataTrain,truthTrain)\n",
      "cm = confusion_matrix(myRF.predict(dataTest), truthTest)\n",
      "print cm\n",
      "print metrics.classification_report(truthTest, myRF.predict(dataTest),target_names=['Dud', 'lQSO'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1451   76]\n",
        " [  41  284]]\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        Dud       0.95      0.97      0.96      1492\n",
        "       lQSO       0.87      0.79      0.83       360\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1852\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Random Forests: Optimized Grid Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import grid_search\n",
      "trialRF = RandomForestClassifier()\n",
      "\n",
      "# parameter values over which we will search\n",
      "parameters = {'n_estimators':(10,50,200),\"max_features\": [\"auto\",2,4],\n",
      "              'criterion':[\"gini\",\"entropy\"],\"min_samples_leaf\": [1,2]}\n",
      "\n",
      "# do a grid search to find the highest 3-fold CV zero-one score\n",
      "tunedRF = grid_search.GridSearchCV(trialRF, parameters, score_func=metrics.accuracy_score,\\\n",
      "                                    n_jobs = -1, cv = 3,verbose=1)\n",
      "optRF = tunedRF.fit(dataTrain, truthTrain)\n",
      "\n",
      "# print the best score and estimator\n",
      "print(optRF.best_score_)\n",
      "print(optRF.best_estimator_)\n",
      "\n",
      "print metrics.classification_report(truthTest, optRF.predict(dataTest),target_names=['Dud', 'lQSO'])\n",
      "cm = confusion_matrix(optRF.predict(dataTest), truthTest)\n",
      "print cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/mbaumer/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing function as ``score_func`` is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''.\n",
        "  self.loss_func, self.score_func, self.scoring)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    3.6s\n",
        "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   11.2s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.944400106411\n",
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion=gini, max_depth=None, max_features=4,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
        "            verbose=0)\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        Dud       0.96      0.97      0.96      1492\n",
        "       lQSO       0.87      0.82      0.85       360\n",
        "\n",
        "avg / total       0.94      0.94      0.94      1852\n",
        "\n",
        "[[1448   64]\n",
        " [  44  296]]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##SVMs (linear and gaussian kernels)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "trialSVM = svm.SVC()\n",
      "\n",
      "# parameter values over which we will search\n",
      "parameters = {'kernel':('linear', 'rbf'), 'class_weight':('auto',None), \\\n",
      "              'gamma':[0.7, 0.5, 0.3, 0.1,  0.01],\n",
      "              'C':[0.1, 2, 4, 5, 10, 20,30]}\n",
      "\n",
      "# do a grid search to find the highest 3-fold CV zero-one score\n",
      "tunedSVM = grid_search.GridSearchCV(trialSVM, parameters, score_func=metrics.accuracy_score,\\\n",
      "                                    n_jobs = -1, cv = 3,verbose=1)\n",
      "optSVM = tunedSVM.fit(dataTrain, truthTrain)\n",
      "\n",
      "# print the best score and estimator\n",
      "print(optSVM.best_score_)\n",
      "print(optSVM.best_estimator_)\n",
      "print metrics.classification_report(truthTest, optSVM.predict(dataTest),target_names=['Dud', 'lQSO'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 140 candidates, totalling 420 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/mbaumer/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing function as ``score_func`` is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''.\n",
        "  self.loss_func, self.score_func, self.scoring)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    1.0s\n",
        "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:    3.3s\n",
        "[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:    7.4s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.937483373238\n",
        "SVC(C=20, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.5,\n",
        "  kernel=rbf, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        Dud       0.95      0.97      0.96      1492\n",
        "       lQSO       0.84      0.77      0.81       360\n",
        "\n",
        "avg / total       0.93      0.93      0.93      1852\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}